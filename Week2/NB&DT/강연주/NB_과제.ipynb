{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayesian Classifier\n",
    "### Q1. Bayes Rule을 이해하고 Naive  Bayes classifier가 사용하는 사후 확률 계산 과정을 서술하세요.\n",
    "\n",
    "- Bayes Rule:   \n",
    "$P(w_i|x) = \\frac{P(x|w_i)|P(w_i)}{P(x)} = \\frac{P(x|w_i) P(w_i)}{\\Sigma_j P(x|w_j)P(w_j)}$\n",
    "  -\n",
    "  - $P(x|w_i)\\text{: 사후 확률, posterior}\\\\\n",
    "P(x|w_i) \\text{: 가능도/우도, likelihood}\\\\\n",
    "P(w_i) \\text{: 사전 확률, prior}\\\\\n",
    "P(x) \\text{: 증거, evidence}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1. 각 특징이 독립적이라는 가정 아래에 진행한다. \n",
    "사전 확률을 계산한 다음 가능도를 계산한다. 모든 클래스에 대해 가능도*사전확률 값을 구한 값을 분모로 두고, 사전확률*가능도를 분자에 두어서 계산한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. Naive Bayes Classification 방법을 이용해서 다음 생성된 리뷰 데이터에 기반한 감정 분석을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this great product! It exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Worst purchase I have ever made. Completel...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is an average product, nothing special but ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great service and who can help but love this d...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terrible experience, I will never buy from thi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I love this great product! It exceeded my expe...  positive\n",
       "1  The Worst purchase I have ever made. Completel...  negative\n",
       "2  It is an average product, nothing special but ...   neutral\n",
       "3  Great service and who can help but love this d...  positive\n",
       "4  Terrible experience, I will never buy from thi...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 리뷰 데이터 생성\n",
    "data = {\n",
    "    'review': [\n",
    "        'I love this great product! It exceeded my expectations.',\n",
    "        'The Worst purchase I have ever made. Completely useless.',\n",
    "        'It is an average product, nothing special but not terrible either.',\n",
    "        'Great service and who can help but love this design? Highly recommend!',\n",
    "        'Terrible experience, I will never buy from this poor brand again.',\n",
    "        'It’s acceptable, but I expected better service, not just an acceptable one.',\n",
    "        'Absolutely wonderful! I am very satisfied with this great service.',\n",
    "        'The quality is poor and it broke after one use. Terrible enough!',\n",
    "        'Acceptable product for the price, but there are better options out there.',\n",
    "        'Great quality and fast shipping with wonderful service! I love it'\n",
    "    ],\n",
    "    'sentiment': [\n",
    "        'positive', 'negative', 'neutral', 'positive', 'negative',\n",
    "        'neutral', 'positive', 'negative', 'neutral', 'positive',\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 리스트 정의\n",
    "stopwords = ['i', 'my', 'am', 'this', 'it', 'its', 'an', 'a', 'the', 'is', 'are', 'and', 'product', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자로 변환\n",
    "    text = text.lower()\n",
    "    # 특수 기호 제거\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # 불용어 제거\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# 모든 리뷰에 대해 전처리 수행\n",
    "df['review'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적인 데이터 전처리가 완료되었습니다!\n",
    "이제부터 직접 나이브 베이지안 분류를 수행해 봅시다.  \n",
    "우리가 분류하고자 하는 문장은 총 두가지 입니다.  \n",
    "전처리가 완료되었다고 치고,   \n",
    "첫번째 문장은 **'love, great, awesome'**,  \n",
    "두번째 문장은 **'terrible, not, never'** 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 확률 $P(positive), P(negative), P(neutral)$을 구합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "positive    0.4\n",
      "negative    0.3\n",
      "neutral     0.3\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 사전 확률 구하는 코드를 작성해주세요.\n",
    "\n",
    "sentiment_counts=df['sentiment'].value_counts()\n",
    "prior_prob=sentiment_counts/len(df)\n",
    "\n",
    "print(prior_prob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love great exceeded expectations</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst purchase have ever made completely useless</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>average nothing special but not terrible either</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great who can help but love design highly reco...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrible experience will never buy from poor b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acceptable but expected better not just accept...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absolutely wonderful very satisfied with great</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quality poor broke after one use terrible enough</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>acceptable for price but there better options ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>great quality fast shipping with wonderful love</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0                   love great exceeded expectations  positive\n",
       "1   worst purchase have ever made completely useless  negative\n",
       "2    average nothing special but not terrible either   neutral\n",
       "3  great who can help but love design highly reco...  positive\n",
       "4  terrible experience will never buy from poor b...  negative\n",
       "5  acceptable but expected better not just accept...   neutral\n",
       "6     absolutely wonderful very satisfied with great  positive\n",
       "7   quality poor broke after one use terrible enough  negative\n",
       "8  acceptable for price but there better options ...   neutral\n",
       "9    great quality fast shipping with wonderful love  positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가능도를 구하기 위한 확률들을 계산합니다.  \n",
    "예: 첫번째 문장 분류를 위해서는, $P(love|positive), P(great|positive), P(awesome|positive)\\\\\n",
    "P(love|negative), P(great|negative), P(awesome|negative)\\\\\n",
    "P(love|neutral), P(great|neutral), P(great|neutral)$를 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 때 CountVectorizer를 사용하여 도출한 단어 벡터를 활용하면 확률들을 간편하게 구할 수 있습니다.  \n",
    "참고: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "review_array = vectorizer.fit_transform(df['review']).toarray()\n",
    "review_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['absolutely', 'acceptable', 'after', 'again', 'average', 'better',\n",
       "       'brand', 'broke', 'but', 'buy', 'can', 'completely', 'design',\n",
       "       'either', 'enough', 'ever', 'exceeded', 'expectations', 'expected',\n",
       "       'experience', 'fast', 'for', 'from', 'great', 'have', 'help',\n",
       "       'highly', 'just', 'love', 'made', 'never', 'not', 'nothing', 'one',\n",
       "       'options', 'out', 'poor', 'price', 'purchase', 'quality',\n",
       "       'recommend', 'satisfied', 'shipping', 'special', 'terrible',\n",
       "       'there', 'use', 'useless', 'very', 'who', 'will', 'with',\n",
       "       'wonderful', 'worst'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'love': 28,\n",
       " 'great': 23,\n",
       " 'exceeded': 16,\n",
       " 'expectations': 17,\n",
       " 'worst': 53,\n",
       " 'purchase': 38,\n",
       " 'have': 24,\n",
       " 'ever': 15,\n",
       " 'made': 29,\n",
       " 'completely': 11,\n",
       " 'useless': 47,\n",
       " 'average': 4,\n",
       " 'nothing': 32,\n",
       " 'special': 43,\n",
       " 'but': 8,\n",
       " 'not': 31,\n",
       " 'terrible': 44,\n",
       " 'either': 13,\n",
       " 'who': 49,\n",
       " 'can': 10,\n",
       " 'help': 25,\n",
       " 'design': 12,\n",
       " 'highly': 26,\n",
       " 'recommend': 40,\n",
       " 'experience': 19,\n",
       " 'will': 50,\n",
       " 'never': 30,\n",
       " 'buy': 9,\n",
       " 'from': 22,\n",
       " 'poor': 36,\n",
       " 'brand': 6,\n",
       " 'again': 3,\n",
       " 'acceptable': 1,\n",
       " 'expected': 18,\n",
       " 'better': 5,\n",
       " 'just': 27,\n",
       " 'one': 33,\n",
       " 'absolutely': 0,\n",
       " 'wonderful': 52,\n",
       " 'very': 48,\n",
       " 'satisfied': 41,\n",
       " 'with': 51,\n",
       " 'quality': 39,\n",
       " 'broke': 7,\n",
       " 'after': 2,\n",
       " 'use': 46,\n",
       " 'enough': 14,\n",
       " 'for': 21,\n",
       " 'price': 37,\n",
       " 'there': 45,\n",
       " 'options': 34,\n",
       " 'out': 35,\n",
       " 'fast': 20,\n",
       " 'shipping': 42}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>average</th>\n",
       "      <th>better</th>\n",
       "      <th>brand</th>\n",
       "      <th>broke</th>\n",
       "      <th>but</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>there</th>\n",
       "      <th>use</th>\n",
       "      <th>useless</th>\n",
       "      <th>very</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment  absolutely  acceptable  after  again  average  better  brand  \\\n",
       "0  positive           0           0      0      0        0       0      0   \n",
       "1  negative           0           0      0      0        0       0      0   \n",
       "2   neutral           0           0      0      0        1       0      0   \n",
       "3  positive           0           0      0      0        0       0      0   \n",
       "4  negative           0           0      0      1        0       0      1   \n",
       "5   neutral           0           2      0      0        0       1      0   \n",
       "6  positive           1           0      0      0        0       0      0   \n",
       "7  negative           0           0      1      0        0       0      0   \n",
       "8   neutral           0           1      0      0        0       1      0   \n",
       "9  positive           0           0      0      0        0       0      0   \n",
       "\n",
       "   broke  but  ...  terrible  there  use  useless  very  who  will  with  \\\n",
       "0      0    0  ...         0      0    0        0     0    0     0     0   \n",
       "1      0    0  ...         0      0    0        1     0    0     0     0   \n",
       "2      0    1  ...         1      0    0        0     0    0     0     0   \n",
       "3      0    1  ...         0      0    0        0     0    1     0     0   \n",
       "4      0    0  ...         1      0    0        0     0    0     1     0   \n",
       "5      0    1  ...         0      0    0        0     0    0     0     0   \n",
       "6      0    0  ...         0      0    0        0     1    0     0     1   \n",
       "7      1    0  ...         1      0    1        0     0    0     0     0   \n",
       "8      0    1  ...         0      2    0        0     0    0     0     0   \n",
       "9      0    0  ...         0      0    0        0     0    0     0     1   \n",
       "\n",
       "   wonderful  worst  \n",
       "0          0      0  \n",
       "1          0      1  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "5          0      0  \n",
       "6          1      0  \n",
       "7          0      0  \n",
       "8          0      0  \n",
       "9          1      0  \n",
       "\n",
       "[10 rows x 55 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_matrix = pd.DataFrame(review_array, columns = vectorizer.get_feature_names_out())\n",
    "frequency_matrix = pd.concat([df['sentiment'], frequency_matrix], axis=1)\n",
    "frequency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n",
      "absolutely      0.0250\n",
      "acceptable      0.0125\n",
      "after           0.0125\n",
      "again           0.0125\n",
      "average         0.0125\n",
      "better          0.0125\n",
      "brand           0.0125\n",
      "broke           0.0125\n",
      "but             0.0250\n",
      "buy             0.0125\n",
      "can             0.0250\n",
      "completely      0.0125\n",
      "design          0.0250\n",
      "either          0.0125\n",
      "enough          0.0125\n",
      "ever            0.0125\n",
      "exceeded        0.0250\n",
      "expectations    0.0250\n",
      "expected        0.0125\n",
      "experience      0.0125\n",
      "fast            0.0250\n",
      "for             0.0125\n",
      "from            0.0125\n",
      "great           0.0625\n",
      "have            0.0125\n",
      "help            0.0250\n",
      "highly          0.0250\n",
      "just            0.0125\n",
      "love            0.0500\n",
      "made            0.0125\n",
      "never           0.0125\n",
      "not             0.0125\n",
      "nothing         0.0125\n",
      "one             0.0125\n",
      "options         0.0125\n",
      "out             0.0125\n",
      "poor            0.0125\n",
      "price           0.0125\n",
      "purchase        0.0125\n",
      "quality         0.0250\n",
      "recommend       0.0250\n",
      "satisfied       0.0250\n",
      "shipping        0.0250\n",
      "special         0.0125\n",
      "terrible        0.0125\n",
      "there           0.0125\n",
      "use             0.0125\n",
      "useless         0.0125\n",
      "very            0.0250\n",
      "who             0.0250\n",
      "will            0.0125\n",
      "with            0.0375\n",
      "wonderful       0.0375\n",
      "worst           0.0125\n",
      "dtype: float64\n",
      "\n",
      "Sentiment: negative\n",
      "absolutely      0.012821\n",
      "acceptable      0.012821\n",
      "after           0.025641\n",
      "again           0.025641\n",
      "average         0.012821\n",
      "better          0.012821\n",
      "brand           0.025641\n",
      "broke           0.025641\n",
      "but             0.012821\n",
      "buy             0.025641\n",
      "can             0.012821\n",
      "completely      0.025641\n",
      "design          0.012821\n",
      "either          0.012821\n",
      "enough          0.025641\n",
      "ever            0.025641\n",
      "exceeded        0.012821\n",
      "expectations    0.012821\n",
      "expected        0.012821\n",
      "experience      0.025641\n",
      "fast            0.012821\n",
      "for             0.012821\n",
      "from            0.025641\n",
      "great           0.012821\n",
      "have            0.025641\n",
      "help            0.012821\n",
      "highly          0.012821\n",
      "just            0.012821\n",
      "love            0.012821\n",
      "made            0.025641\n",
      "never           0.025641\n",
      "not             0.012821\n",
      "nothing         0.012821\n",
      "one             0.025641\n",
      "options         0.012821\n",
      "out             0.012821\n",
      "poor            0.038462\n",
      "price           0.012821\n",
      "purchase        0.025641\n",
      "quality         0.025641\n",
      "recommend       0.012821\n",
      "satisfied       0.012821\n",
      "shipping        0.012821\n",
      "special         0.012821\n",
      "terrible        0.038462\n",
      "there           0.012821\n",
      "use             0.025641\n",
      "useless         0.025641\n",
      "very            0.012821\n",
      "who             0.012821\n",
      "will            0.025641\n",
      "with            0.012821\n",
      "wonderful       0.012821\n",
      "worst           0.025641\n",
      "dtype: float64\n",
      "\n",
      "Sentiment: neutral\n",
      "absolutely      0.012821\n",
      "acceptable      0.051282\n",
      "after           0.012821\n",
      "again           0.012821\n",
      "average         0.025641\n",
      "better          0.038462\n",
      "brand           0.012821\n",
      "broke           0.012821\n",
      "but             0.051282\n",
      "buy             0.012821\n",
      "can             0.012821\n",
      "completely      0.012821\n",
      "design          0.012821\n",
      "either          0.025641\n",
      "enough          0.012821\n",
      "ever            0.012821\n",
      "exceeded        0.012821\n",
      "expectations    0.012821\n",
      "expected        0.025641\n",
      "experience      0.012821\n",
      "fast            0.012821\n",
      "for             0.025641\n",
      "from            0.012821\n",
      "great           0.012821\n",
      "have            0.012821\n",
      "help            0.012821\n",
      "highly          0.012821\n",
      "just            0.025641\n",
      "love            0.012821\n",
      "made            0.012821\n",
      "never           0.012821\n",
      "not             0.038462\n",
      "nothing         0.025641\n",
      "one             0.025641\n",
      "options         0.025641\n",
      "out             0.025641\n",
      "poor            0.012821\n",
      "price           0.025641\n",
      "purchase        0.012821\n",
      "quality         0.012821\n",
      "recommend       0.012821\n",
      "satisfied       0.012821\n",
      "shipping        0.012821\n",
      "special         0.025641\n",
      "terrible        0.025641\n",
      "there           0.038462\n",
      "use             0.012821\n",
      "useless         0.012821\n",
      "very            0.012821\n",
      "who             0.012821\n",
      "will            0.012821\n",
      "with            0.012821\n",
      "wonderful       0.012821\n",
      "worst           0.012821\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_conditional_probabilities(frequency_matrix):\n",
    "    word_probabilities = {}\n",
    "    sentiments = frequency_matrix['sentiment'].unique()\n",
    "\n",
    "    for sentiment in sentiments:\n",
    "        sentiment_data = frequency_matrix[frequency_matrix['sentiment'] == sentiment]\n",
    "        total_words = sentiment_data.iloc[:, 1:].sum().sum()  # 해당 sentiment의 전체 단어 수\n",
    "        word_counts = sentiment_data.iloc[:, 1:].sum()  # 각 단어의 등장 빈도\n",
    "        conditional_probabilities = (word_counts + 1) / (total_words + len(word_counts))  # Add-1 Smoothing 적용\n",
    "        word_probabilities[sentiment] = conditional_probabilities\n",
    "\n",
    "    return word_probabilities\n",
    "\n",
    "word_probabilities = compute_conditional_probabilities(frequency_matrix)\n",
    "\n",
    "# 결과 출력\n",
    "for sentiment, probs in word_probabilities.items():\n",
    "    print(f\"Sentiment: {sentiment}\")\n",
    "    print(probs)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "독립성 가정을 이용하여 가능도(likelihood)를 구합니다.  \n",
    "첫번째 문장 예시: $P(love, great, awesome|positive), P(love, great, awesome|negative), P(love, great, awesome|neutral)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihoods for the review 'love great exceeded expectations':\n",
      "{'positive': 1.9531250000000005e-06, 'negative': 2.7016033691803677e-08, 'neutral': 2.7016033691803677e-08}\n",
      "Likelihoods for the review 'worst purchase have ever made completely useless':\n",
      "{'positive': 4.768371582031252e-14, 'negative': 7.286982907143727e-12, 'neutral': 5.692955396206037e-14}\n",
      "Likelihoods for the review 'average nothing special but not terrible either':\n",
      "{'positive': 9.536743164062505e-14, 'negative': 1.7078866188618113e-13, 'neutral': 2.1860948721431184e-11}\n",
      "Likelihoods for the review 'great who can help but love design highly recommend':\n",
      "{'positive': 1.907348632812501e-14, 'negative': 9.357257390213735e-18, 'neutral': 3.742902956085494e-17}\n",
      "Likelihoods for the review 'terrible experience will never buy from poor brand again':\n",
      "{'positive': 7.450580596923832e-18, 'negative': 1.0779560513526225e-14, 'neutral': 1.871451478042747e-17}\n",
      "Likelihoods for the review 'acceptable but expected better not just acceptable one':\n",
      "{'positive': 1.1920928955078131e-15, 'negative': 1.4597321528733428e-15, 'neutral': 3.3632228802201825e-12}\n",
      "Likelihoods for the review 'absolutely wonderful very satisfied with great':\n",
      "{'positive': 1.3732910156250003e-09, 'negative': 4.440505209040709e-12, 'neutral': 4.440505209040709e-12}\n",
      "Likelihoods for the review 'quality poor broke after one use terrible enough':\n",
      "{'positive': 1.1920928955078131e-15, 'negative': 4.204028600275228e-13, 'neutral': 2.9194643057466856e-15}\n",
      "Likelihoods for the review 'acceptable for price but there better options out there':\n",
      "{'positive': 1.4901161193847666e-17, 'negative': 9.357257390213735e-18, 'neutral': 6.467736308115736e-14}\n",
      "Likelihoods for the review 'great quality fast shipping with wonderful love':\n",
      "{'positive': 6.866455078125001e-11, 'negative': 1.1385910792412073e-13, 'neutral': 5.692955396206037e-14}\n"
     ]
    }
   ],
   "source": [
    "# 가능도 구하는 코드를 작성해주세요.\n",
    "\n",
    "def compute_likelihood(review, word_probabilities):\n",
    "    review_words = vectorizer.transform([review]).toarray().flatten()\n",
    "    likelihoods = {}\n",
    "\n",
    "    for sentiment, probs in word_probabilities.items():\n",
    "        likelihood = 1\n",
    "        for word, count in zip(vectorizer.get_feature_names_out(), review_words):\n",
    "            likelihood *= probs.get(word, 1) ** count\n",
    "        likelihoods[sentiment] = likelihood\n",
    "\n",
    "    return likelihoods\n",
    "\n",
    "# 테스트 리뷰에 대한 가능도 계산\n",
    "for i in range(0, len(df)):\n",
    "    \n",
    "    review_test = df['review'][i]\n",
    "    likelihoods = compute_likelihood(review_test, word_probabilities)\n",
    "    print(f\"Likelihoods for the review '{review_test}':\")\n",
    "    print(likelihoods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 구한 사전 확률과 가능도를 이용하여 타겟 문장이 positive, negative, neutral일 확률을 구하고 최종적으로 어떤 감성일지 분석해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final probabilities for the first review 'love great exceeded expectations':\n",
      "P(positive|review1) = 0.9796734282160766\n",
      "P(negative|review1) = 0.010163285891961726\n",
      "P(neutral|review1) = 0.010163285891961726\n",
      "\n",
      "\n",
      "Final probabilities for the second review 'worst purchase have ever made completely useless':\n",
      "P(positive|review2) = 0.008582972279803123\n",
      "P(negative|review2) = 0.9837316244045365\n",
      "P(neutral|review2) = 0.007685403315660442\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 최종 확률 구하는 코드를 작성해주세요.\n",
    "# 첫번째 문장\n",
    "# P(positive|target_review1)\n",
    "\n",
    "# P(negative|target_review1)\n",
    "\n",
    "# P(neutral|target_review1)\n",
    "\n",
    "# 두번째 문장\n",
    "# P(positive|target_review2)\n",
    "\n",
    "# P(negative|target_review2)\n",
    "\n",
    "# P(neutral|target_review2)\n",
    "\n",
    "\n",
    "# 사전 확률 계산\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "prior_prob = sentiment_counts / len(df)\n",
    "\n",
    "def compute_final_probabilities(review, word_probabilities, prior_prob):\n",
    "    likelihoods = compute_likelihood(review, word_probabilities)\n",
    "    final_probabilities = {}\n",
    "\n",
    "    # 각 감정에 대한 사후 확률 계산\n",
    "    total_likelihood = sum(likelihoods[sentiment] * prior_prob[sentiment] for sentiment in likelihoods)\n",
    "    for sentiment in likelihoods:\n",
    "        posterior_prob = (likelihoods[sentiment] * prior_prob[sentiment]) / total_likelihood\n",
    "        final_probabilities[sentiment] = posterior_prob\n",
    "\n",
    "    return final_probabilities\n",
    "\n",
    "# 첫 번째 문장에 대한 최종 확률 계산\n",
    "target_review1 = df['review'][0]\n",
    "final_probabilities1 = compute_final_probabilities(target_review1, word_probabilities, prior_prob)\n",
    "\n",
    "print(f\"Final probabilities for the first review '{target_review1}':\")\n",
    "for sentiment, prob in final_probabilities1.items():\n",
    "    print(f\"P({sentiment}|review1) = {prob}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 두 번째 문장에 대한 최종 확률 계산\n",
    "target_review2 = df['review'][1]\n",
    "final_probabilities2 = compute_final_probabilities(target_review2, word_probabilities, prior_prob)\n",
    "\n",
    "print(f\"Final probabilities for the second review '{target_review2}':\")\n",
    "for sentiment, prob in final_probabilities2.items():\n",
    "    print(f\"P({sentiment}|review2) = {prob}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-1.   \n",
    "Target review1의 분류 결과:positive\n",
    "Target review2의 분류 결과:negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-2. 나이브 베이지안 기반 확률을 구하는 과정에서 어떤 문제점을 발견할 수 있었나요? 그리고 그 문제를 해결하기 위한 방법에 대해 간략하게 조사 및 서술해 주세요. (힌트: Laplace smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2-2. 제로 확률 문제, 특정 단어가 훈련 데이터의 특정 클래스에서 전혀 나타나지 않는 경우 발생한다. 이 경우 나이브 베이지안 모델에서는 해당 단어의 조건부 확률을 0으로 계산하게 된다. 이로 인해 전체 확률이 0이 되어서 모델 예측 성능이 크게 저하 된다. 이를 해결하기 위해 라플라스 스무딩을 사용할 수 있다. 이는 모든 단어가 적어도 한 번은 나타난 것처럼 만들어 주는 기법이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
